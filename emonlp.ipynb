{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":61603,"databundleVersionId":6655672,"sourceType":"competition"}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n%pip install -U \"tensorflow-text==2.13.*\"\n%pip install \"tf-models-official==2.13.*\"\n%pip install transformers\n%pip install sentencepiece\n%pip install sacremoses\n%pip install --upgrade pip\n%pip install --disable-pip-version-check \\\n    torch==1.13.1 \\\n    torchdata==0.5.1 --quiet\n\n%pip install \\\n    transformers==4.27.2 \\\n    datasets==2.11.0 \\\n    evaluate==0.4.0 \\\n    rouge_score==0.1.2 \\\n    loralib==0.1.1 \\\n    peft==0.3.0 --quiet\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_text as text\n# Helps free memory using collect() method.\nimport gc \nfrom official.nlp import optimization\n\ntf.get_logger().setLevel('ERROR')\n\nfrom datasets import load_dataset\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\nimport torch\nimport time\nimport evaluate\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport datasets\nfrom datasets import Dataset, DatasetDict\n\nimport random\nimport math\n\nfrom peft import LoraConfig, get_peft_model, TaskType\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-07T19:26:01.577213Z","iopub.execute_input":"2024-06-07T19:26:01.577917Z","iopub.status.idle":"2024-06-07T19:31:09.238671Z","shell.execute_reply.started":"2024-06-07T19:26:01.577875Z","shell.execute_reply":"2024-06-07T19:31:09.237874Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting tensorflow-text==2.13.*\n  Downloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-text==2.13.*) (0.12.0)\nCollecting tensorflow<2.14,>=2.13.0 (from tensorflow-text==2.13.*)\n  Downloading tensorflow-2.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.7/479.7 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (23.5.26)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.51.1)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.9.0)\nCollecting keras<2.14,>=2.13.1 (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*)\n  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (16.0.0)\nRequirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.23.5)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (68.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.16.0)\nCollecting tensorboard<2.14,>=2.13 (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*)\n  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*)\n  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.3.0)\nCollecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*)\n  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.32.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.40.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.20.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.4.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.3.7)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.0.9)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (4.9)\nRequirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.26.15)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2023.7.22)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.1.3)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.2.2)\nInstalling collected packages: typing-extensions, tensorflow-estimator, keras, tensorboard, tensorflow, tensorflow-text\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.6.3\n    Uninstalling typing_extensions-4.6.3:\n      Successfully uninstalled typing_extensions-4.6.3\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.12.0\n    Uninstalling tensorflow-estimator-2.12.0:\n      Successfully uninstalled tensorflow-estimator-2.12.0\n  Attempting uninstall: keras\n    Found existing installation: keras 2.12.0\n    Uninstalling keras-2.12.0:\n      Successfully uninstalled keras-2.12.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.12.3\n    Uninstalling tensorboard-2.12.3:\n      Successfully uninstalled tensorboard-2.12.3\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.12.0\n    Uninstalling tensorflow-2.12.0:\n      Successfully uninstalled tensorflow-2.12.0\n  Attempting uninstall: tensorflow-text\n    Found existing installation: tensorflow-text 2.12.1\n    Uninstalling tensorflow-text-2.12.1:\n      Successfully uninstalled tensorflow-text-2.12.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\nchex 0.1.82 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\npydantic-core 2.6.3 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.2 which is incompatible.\ntensorflow-decision-forests 1.4.0 requires tensorflow~=2.12.0, but you have tensorflow 2.13.1 which is incompatible.\nydata-profiling 4.3.1 requires scipy<1.11,>=1.4.1, but you have scipy 1.11.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.13.1 tensorboard-2.13.0 tensorflow-2.13.1 tensorflow-estimator-2.13.0 tensorflow-text-2.13.0 typing-extensions-4.5.0\nNote: you may need to restart the kernel to use updated packages.\nCollecting tf-models-official==2.13.*\n  Downloading tf_models_official-2.13.2-py2.py3-none-any.whl (2.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: Cython in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.13.*) (0.29.35)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.13.*) (9.5.0)\nCollecting gin-config (from tf-models-official==2.13.*)\n  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.13.*) (2.97.0)\nCollecting immutabledict (from tf-models-official==2.13.*)\n  Downloading immutabledict-4.2.0-py3-none-any.whl (4.7 kB)\nRequirement already satisfied: kaggle>=1.3.9 in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.13.*) (1.5.16)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.13.*) (3.7.2)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.13.*) (1.23.5)\nRequirement already satisfied: oauth2client in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.13.*) (4.1.3)\nRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.13.*) (4.8.0.76)\nRequirement already satisfied: pandas>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.13.*) (2.0.2)\nRequirement already satisfied: psutil>=5.4.3 in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.13.*) (5.9.3)\nRequirement already satisfied: py-cpuinfo>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.13.*) (9.0.0)\nCollecting pycocotools (from tf-models-official==2.13.*)\n  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pyyaml>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.13.*) (6.0)\nCollecting sacrebleu (from tf-models-official==2.13.*)\n  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.13.*) (1.11.2)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.13.*) (0.1.99)\nCollecting seqeval (from tf-models-official==2.13.*)\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.13.*) (1.16.0)\nRequirement already satisfied: tensorflow-datasets in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.13.*) (4.9.2)\nRequirement already satisfied: tensorflow-hub>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.13.*) (0.12.0)\nCollecting tensorflow-model-optimization>=0.4.1 (from tf-models-official==2.13.*)\n  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tensorflow-text~=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.13.*) (2.13.0)\nRequirement already satisfied: tensorflow~=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.13.*) (2.13.1)\nCollecting tf-slim>=1.1.0 (from tf-models-official==2.13.*)\n  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: httplib2<1.dev0,>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (0.21.0)\nRequirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (2.20.0)\nRequirement already satisfied: google-auth-httplib2>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (0.1.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (2.11.1)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (3.0.1)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (2023.7.22)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (2.8.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (4.66.1)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (8.0.1)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (1.26.15)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (6.0.0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.22.0->tf-models-official==2.13.*) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.22.0->tf-models-official==2.13.*) (2023.3)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (23.5.26)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.51.1)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (3.9.0)\nRequirement already satisfied: keras<2.14,>=2.13.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.13.1)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (16.0.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (68.0.0)\nRequirement already satisfied: tensorboard<2.14,>=2.13 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.13.0)\nRequirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.13.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.3.0)\nRequirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (4.5.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (0.32.0)\nRequirement already satisfied: dm-tree~=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.13.*) (0.1.8)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->tf-models-official==2.13.*) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->tf-models-official==2.13.*) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->tf-models-official==2.13.*) (4.40.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->tf-models-official==2.13.*) (1.4.4)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->tf-models-official==2.13.*) (3.0.9)\nRequirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.10/site-packages (from oauth2client->tf-models-official==2.13.*) (0.4.8)\nRequirement already satisfied: pyasn1-modules>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from oauth2client->tf-models-official==2.13.*) (0.2.7)\nRequirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from oauth2client->tf-models-official==2.13.*) (4.9)\nCollecting portalocker (from sacrebleu->tf-models-official==2.13.*)\n  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu->tf-models-official==2.13.*) (2023.6.3)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu->tf-models-official==2.13.*) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu->tf-models-official==2.13.*) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu->tf-models-official==2.13.*) (4.9.3)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval->tf-models-official==2.13.*) (1.2.2)\nRequirement already satisfied: array-record in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.13.*) (0.4.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.13.*) (8.1.7)\nRequirement already satisfied: etils[enp,epath]>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.13.*) (1.3.0)\nRequirement already satisfied: promise in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.13.*) (2.3)\nRequirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.13.*) (0.14.0)\nRequirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.13.*) (0.10.2)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow~=2.13.0->tf-models-official==2.13.*) (0.40.0)\nRequirement already satisfied: importlib_resources in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official==2.13.*) (5.12.0)\nRequirement already satisfied: zipp in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official==2.13.*) (3.15.0)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.13.*) (1.59.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.13.*) (4.2.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle>=1.3.9->tf-models-official==2.13.*) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle>=1.3.9->tf-models-official==2.13.*) (3.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.13.*) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.13.*) (3.1.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (3.4.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (2.3.7)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle>=1.3.9->tf-models-official==2.13.*) (0.5.1)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.13.*) (1.3)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (2.1.3)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (3.2.2)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16165 sha256=754084fd0b88e24431bad1cfa5f02c485a2760d104ef8d2c3776886112b59fc8\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built seqeval\nInstalling collected packages: gin-config, tf-slim, tensorflow-model-optimization, portalocker, immutabledict, sacrebleu, seqeval, pycocotools, tf-models-official\nSuccessfully installed gin-config-0.5.0 immutabledict-4.2.0 portalocker-2.8.2 pycocotools-2.0.7 sacrebleu-2.4.2 seqeval-1.2.2 tensorflow-model-optimization-0.8.0 tf-models-official-2.13.2 tf-slim-1.1.0\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\nNote: you may need to restart the kernel to use updated packages.\nCollecting sacremoses\n  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacremoses) (2023.6.3)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sacremoses) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from sacremoses) (1.3.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sacremoses) (4.66.1)\nInstalling collected packages: sacremoses\nSuccessfully installed sacremoses-0.1.1\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.1.2)\nCollecting pip\n  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.1.2\n    Uninstalling pip-23.1.2:\n      Successfully uninstalled pip-23.1.2\nSuccessfully installed pip-24.0\nNote: you may need to restart the kernel to use updated packages.\nNote: you may need to restart the kernel to use updated packages.\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\npathos 0.3.1 requires dill>=0.3.7, but you have dill 0.3.6 which is incompatible.\npathos 0.3.1 requires multiprocess>=0.70.15, but you have multiprocess 0.70.14 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n/kaggle/input/emonlp-interiit-techsoc-aiclub/sample_submission.csv\n/kaggle/input/emonlp-interiit-techsoc-aiclub/train.csv\n/kaggle/input/emonlp-interiit-techsoc-aiclub/test.csv\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Input\n","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/emonlp-interiit-techsoc-aiclub/train.csv\")\n\ntrain_df, val_df = train_test_split(train_data, test_size=0.2, random_state=42, shuffle=True)\nprint(train_df.head(5))\n\ntrain_ds = Dataset.from_pandas(train_df, preserve_index=False)\nval_ds = Dataset.from_pandas(val_df, preserve_index=False)\nds = DatasetDict()\n\nds['train'] = train_ds\nds['validation'] = val_ds\nprint(ds)\n\nx_train_str = list(train_data.Text)\ny_train_str = train_data.Emotion","metadata":{"execution":{"iopub.status.busy":"2024-06-07T19:36:12.208328Z","iopub.execute_input":"2024-06-07T19:36:12.209200Z","iopub.status.idle":"2024-06-07T19:36:12.227665Z","shell.execute_reply.started":"2024-06-07T19:36:12.209162Z","shell.execute_reply":"2024-06-07T19:36:12.226762Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"                                                 Text  Emotion\n31  i find every body beautiful and only want peop...      joy\n3   i workout every morning before and feel fabulo...      joy\n52  i tried to fill it by befriending people that ...     love\n17  i crave as i fall into submission and i did no...  sadness\n8    i personalities that can feel pain and suffering  sadness\nDatasetDict({\n    train: Dataset({\n        features: ['Text', 'Emotion'],\n        num_rows: 48\n    })\n    validation: Dataset({\n        features: ['Text', 'Emotion'],\n        num_rows: 12\n    })\n})\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Processing labels","metadata":{}},{"cell_type":"code","source":"labels = []\n# For counting the number of unique labels.\nfor x in y_train_str:\n    if x not in labels:\n        labels.append(x)\n        \nlabels_dictionary = {}\n\nfor i in range(len(labels)):\n    labels_dictionary[labels[i]]  = i\n\n# Setting up training labels by encoding them with integers.\ny_train = np.ones(60)\nfor i, y in enumerate(y_train_str):\n    y_train[i] = labels_dictionary[y]\n\n# Stores the reverse relationship of labels and their encoding, useful after output.\nlabels_dictionary_reverse = {v: k for k, v in labels_dictionary.items()}\n    \nprint(\"No. of labels in dataset : \", len(labels))","metadata":{"execution":{"iopub.status.busy":"2024-06-07T19:36:15.998818Z","iopub.execute_input":"2024-06-07T19:36:15.999526Z","iopub.status.idle":"2024-06-07T19:36:16.006736Z","shell.execute_reply.started":"2024-06-07T19:36:15.999494Z","shell.execute_reply":"2024-06-07T19:36:16.005682Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"No. of labels in dataset :  6\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Loading BERT model and preprocessor.","metadata":{}},{"cell_type":"code","source":"tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1'\n\ntfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n\nbert_model = hub.KerasLayer(tfhub_handle_encoder)\nbert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T19:12:17.379984Z","iopub.execute_input":"2024-06-07T19:12:17.380255Z","iopub.status.idle":"2024-06-07T19:12:38.896579Z","shell.execute_reply.started":"2024-06-07T19:12:17.380232Z","shell.execute_reply":"2024-06-07T19:12:38.895794Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Freeing up some memory.\ndel train_data, y_train_str\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-06-07T19:31:09.288575Z","iopub.execute_input":"2024-06-07T19:31:09.288902Z","iopub.status.idle":"2024-06-07T19:31:09.544138Z","shell.execute_reply.started":"2024-06-07T19:31:09.288870Z","shell.execute_reply":"2024-06-07T19:31:09.543186Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"30"},"metadata":{}}]},{"cell_type":"markdown","source":"## Loading Flan T5 and Tokenizer\n","metadata":{}},{"cell_type":"code","source":"model_name='google/flan-t5-base'\noriginal_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T19:36:19.504979Z","iopub.execute_input":"2024-06-07T19:36:19.505371Z","iopub.status.idle":"2024-06-07T19:37:15.675400Z","shell.execute_reply.started":"2024-06-07T19:36:19.505340Z","shell.execute_reply":"2024-06-07T19:37:15.674591Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4387d117ce1d44709afb952f732ab13c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47cfec2bd6bc4a318ab7adf0c506edbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"507231e1a55e40b28d129fc7f162a21b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2927caa5e204cfa97f73dad3e1c7d9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"404c28f9fe6b4b35aea18dbfeeb83ad1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a616f4351dd141ab872529f2cc79fabc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6cf4ddbfae345dc8b6aa172533644f2"}},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_function(dataset):\n    prompt = ['''Identify the sentiment of the following dialogue from the given labels. Provide a one-word sentiment only.\nLabels: {}\n\nDialogue: {}\nSentiment:\n'''.format(labels, text) for text in dataset['Text']]\n    dataset['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n    dataset['labels'] = tokenizer(dataset[\"Emotion\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n    \n    return dataset\n\ntokenized_datasets = ds.map(tokenize_function, batched=True)\ntokenized_datasets = tokenized_datasets.remove_columns(['Text', 'Emotion'])","metadata":{"execution":{"iopub.status.busy":"2024-06-07T19:37:15.677181Z","iopub.execute_input":"2024-06-07T19:37:15.677594Z","iopub.status.idle":"2024-06-07T19:37:15.825095Z","shell.execute_reply.started":"2024-06-07T19:37:15.677560Z","shell.execute_reply":"2024-06-07T19:37:15.824185Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/48 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/12 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"markdown","source":"## Data Augmentation\nI am augmenting data using translation-detranslation. This leads to slight but considerable changes in the sentence structure without change in overall emotion. Doing this with 2 separate languages allows me to increase the size of my dataset by 3 times.","metadata":{}},{"cell_type":"code","source":"from transformers import MarianMTModel, MarianTokenizer\n# Get the name of the first model\nfirst_model_name1 = 'Helsinki-NLP/opus-mt-en-zh'\nfirst_model_name2 = 'Helsinki-NLP/opus-mt-en-fr'\n\n# Get the tokenizer\nfirst_model_tkn1 = MarianTokenizer.from_pretrained(first_model_name1)\nfirst_model_tkn2 = MarianTokenizer.from_pretrained(first_model_name2)\n\n# Load the pretrained model based on the name\nfirst_model1 = MarianMTModel.from_pretrained(first_model_name1)\nfirst_model2 = MarianMTModel.from_pretrained(first_model_name2)\n\n# Get the name of the second model\nsecond_model_name1 = 'Helsinki-NLP/opus-mt-zh-en'\nsecond_model_name2 = 'Helsinki-NLP/opus-mt-fr-en'\n\n# Get the tokenizer\nsecond_model_tkn1 = MarianTokenizer.from_pretrained(second_model_name1)\nsecond_model_tkn2 = MarianTokenizer.from_pretrained(second_model_name2)\n\n\n# Load the pretrained model based on the name\nsecond_model1 = MarianMTModel.from_pretrained(second_model_name1)\nsecond_model2 = MarianMTModel.from_pretrained(second_model_name2)\n\n\ndef perform_translation(batch_texts, model, tokenizer, language=\"fr\"):\n    # Prepare the text data into appropriate format for the model\n    formated_batch_texts = format_batch_texts(language, batch_texts)\n    \n    # Generate translation using model\n    translated = model.generate(**tokenizer(formated_batch_texts, return_tensors=\"pt\", padding=True))\n\n    # Convert the generated tokens indices back into text\n    translated_texts = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n    \n    return translated_texts\n\ndef format_batch_texts(language_code, batch_texts):\n  \n  formated_batch = [\">>{}<< {}\".format(language_code, text) for text in batch_texts]\n\n  return formated_batch\n\n\nx_train1 = []\nx_train_aug = perform_translation(x_train_str, first_model1, first_model_tkn1)\nx_train_aug1 = perform_translation(x_train_aug, second_model1, second_model_tkn1)\nx_train1.extend(x_train_aug1)\n\nx_train_aug = perform_translation(x_train_str, first_model2, first_model_tkn2)\nx_train_aug1 = perform_translation(x_train_aug, second_model2, second_model_tkn2)\nx_train1.extend(x_train_aug1)\n\nx_train = []\nfor x in x_train1:\n    x_train.append(\"\".join(ch for ch in x.lower() if (ch.isalnum() or ch.isspace())))\nx_train.extend(x_train_str)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T18:21:00.720627Z","iopub.execute_input":"2023-10-04T18:21:00.720962Z","iopub.status.idle":"2023-10-04T18:24:56.472885Z","shell.execute_reply.started":"2023-10-04T18:21:00.720931Z","shell.execute_reply":"2023-10-04T18:24:56.471943Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/source.spm:   0%|          | 0.00/806k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a59b89161fd64070850c7136cbc99de8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/target.spm:   0%|          | 0.00/805k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70b9c2ab7fd247e082aa3d453c18b147"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.62M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0b90c80656a4f5a989c5bd2ba0ce303"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"696f52d2a01648b19ec2a4ee39921a9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9defbdda497431db1ac847ee0f53b1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/source.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74673b111d58426abce08760eb5d793e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/target.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff2857027f07423a963407def3b80220"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07085f4428bc4ceb98d465a0a02ad337"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e63a80eef04425d82ed17db0e1a7149"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"519e475f14a4435cbe64a9434de331c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/312M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"781f0750292c4cce8c8e36e7da584dce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"095b2c1364a54b81ac5635d42c8faf94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f7ac447b6d748da9ce5954b2afdba99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"188f76657c194e07a627fa42ce50d1b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/source.spm:   0%|          | 0.00/805k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52fd1fcf36714d1fa76cafe8fd43151f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/target.spm:   0%|          | 0.00/807k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75892cffbccc44a4be05be36023e35a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.62M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f865ddebbf0445dba63250c50eb0a2df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5aaa33897d84cab93dce9bb354d7789"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d73c822bc244cf6983eb739a82bb8ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/source.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02e85b0d9b8c437689ec023dcf0250c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/target.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3a0e33b7b724421a1960a27c6afcc4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20f4539395bd449f8bd61a53da829989"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8025a981de0a48e7b9fc09a67db21749"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bb497e8bac14417903a2e664e34954a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/312M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc88ca49c19e4787a20f95a052c4195d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10ed1b1fed5c4a8b8b1843c93469aa2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b51f4e644fb4350a6831cf6e0d09084"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"923b15e0d78b40fab242ed2456f25b41"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Making train-test split for BERT with data augmented.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x_train, 3*list(y_train), test_size=0.2, random_state=17)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T18:24:56.474591Z","iopub.execute_input":"2023-10-04T18:24:56.475271Z","iopub.status.idle":"2023-10-04T18:24:56.980845Z","shell.execute_reply.started":"2023-10-04T18:24:56.475237Z","shell.execute_reply":"2023-10-04T18:24:56.979951Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Fine-tuning Section","metadata":{}},{"cell_type":"markdown","source":"## Tensorflow BERT","metadata":{}},{"cell_type":"code","source":"text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\npreprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\nencoder_inputs = preprocessing_layer(text_input)\nencoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\noutputs = encoder(encoder_inputs)\nnet = outputs['pooled_output']\nnet = tf.keras.layers.Dropout(0.1)(net)\ntf.keras.layers.BatchNormalization(synchronized=True)\noutput = tf.keras.layers.Dense(6, activation='softmax', kernel_regularizer = tf.keras.regularizers.L1L2(l1=0.02, l2=0.01), name='classifier')(net)\nclassifier_model = tf.keras.Model(text_input, output)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T18:24:56.982046Z","iopub.execute_input":"2023-10-04T18:24:56.982923Z","iopub.status.idle":"2023-10-04T18:25:10.936688Z","shell.execute_reply.started":"2023-10-04T18:24:56.982890Z","shell.execute_reply":"2023-10-04T18:25:10.935750Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False)\nmetrics = tf.keras.metrics.SparseCategoricalAccuracy()\ncallbacks = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", verbose=1, patience=3, restore_best_weights=True)\n\nepochs = 70\nsteps_per_epoch = len(x_train)\nnum_train_steps = steps_per_epoch * epochs\nnum_warmup_steps = int(0.1*num_train_steps)\n\ninit_lr = 3e-5\noptimizer = optimization.create_optimizer(init_lr=init_lr,\n                                          num_train_steps=num_train_steps,\n                                          num_warmup_steps=num_warmup_steps,\n                                          optimizer_type='adamw')","metadata":{"execution":{"iopub.status.busy":"2023-10-04T18:25:10.938126Z","iopub.execute_input":"2023-10-04T18:25:10.938454Z","iopub.status.idle":"2023-10-04T18:25:10.950834Z","shell.execute_reply.started":"2023-10-04T18:25:10.938401Z","shell.execute_reply":"2023-10-04T18:25:10.949978Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"classifier_model.compile(optimizer = optimizer, metrics = metrics, loss = loss)\nclassifier_model.fit(x = np.asarray(x_train),y = np.asarray(y_train), epochs = epochs, validation_split = 0.1, callbacks = callbacks)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T18:25:10.954240Z","iopub.execute_input":"2023-10-04T18:25:10.954928Z","iopub.status.idle":"2023-10-04T18:28:48.436857Z","shell.execute_reply.started":"2023-10-04T18:25:10.954862Z","shell.execute_reply":"2023-10-04T18:28:48.435665Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/70\n5/5 [==============================] - 22s 987ms/step - loss: 6.2281 - sparse_categorical_accuracy: 0.1628 - val_loss: 6.2881 - val_sparse_categorical_accuracy: 0.1333\nEpoch 2/70\n5/5 [==============================] - 2s 487ms/step - loss: 6.2545 - sparse_categorical_accuracy: 0.2093 - val_loss: 6.2742 - val_sparse_categorical_accuracy: 0.1333\nEpoch 3/70\n5/5 [==============================] - 3s 558ms/step - loss: 6.2141 - sparse_categorical_accuracy: 0.1938 - val_loss: 6.2536 - val_sparse_categorical_accuracy: 0.1333\nEpoch 4/70\n5/5 [==============================] - 3s 520ms/step - loss: 6.1444 - sparse_categorical_accuracy: 0.1783 - val_loss: 6.2257 - val_sparse_categorical_accuracy: 0.0667\nEpoch 5/70\n5/5 [==============================] - 2s 447ms/step - loss: 6.1707 - sparse_categorical_accuracy: 0.1628 - val_loss: 6.1963 - val_sparse_categorical_accuracy: 0.0667\nEpoch 6/70\n5/5 [==============================] - 3s 529ms/step - loss: 6.1330 - sparse_categorical_accuracy: 0.1473 - val_loss: 6.1619 - val_sparse_categorical_accuracy: 0.0667\nEpoch 7/70\n5/5 [==============================] - 3s 510ms/step - loss: 6.0737 - sparse_categorical_accuracy: 0.1705 - val_loss: 6.1284 - val_sparse_categorical_accuracy: 0.0667\nEpoch 8/70\n5/5 [==============================] - 2s 450ms/step - loss: 6.1055 - sparse_categorical_accuracy: 0.1938 - val_loss: 6.0968 - val_sparse_categorical_accuracy: 0.0667\nEpoch 9/70\n5/5 [==============================] - 3s 538ms/step - loss: 6.0430 - sparse_categorical_accuracy: 0.1550 - val_loss: 6.0687 - val_sparse_categorical_accuracy: 0.0667\nEpoch 10/70\n5/5 [==============================] - 3s 506ms/step - loss: 6.0076 - sparse_categorical_accuracy: 0.2093 - val_loss: 6.0431 - val_sparse_categorical_accuracy: 0.0667\nEpoch 11/70\n5/5 [==============================] - 3s 534ms/step - loss: 5.9463 - sparse_categorical_accuracy: 0.2248 - val_loss: 6.0172 - val_sparse_categorical_accuracy: 0.0667\nEpoch 12/70\n5/5 [==============================] - 3s 506ms/step - loss: 5.9296 - sparse_categorical_accuracy: 0.2636 - val_loss: 5.9968 - val_sparse_categorical_accuracy: 0.2000\nEpoch 13/70\n5/5 [==============================] - 3s 544ms/step - loss: 5.9156 - sparse_categorical_accuracy: 0.2403 - val_loss: 5.9748 - val_sparse_categorical_accuracy: 0.2000\nEpoch 14/70\n5/5 [==============================] - 3s 528ms/step - loss: 5.8681 - sparse_categorical_accuracy: 0.2791 - val_loss: 5.9544 - val_sparse_categorical_accuracy: 0.2667\nEpoch 15/70\n5/5 [==============================] - 3s 529ms/step - loss: 5.8273 - sparse_categorical_accuracy: 0.3101 - val_loss: 5.9403 - val_sparse_categorical_accuracy: 0.2667\nEpoch 16/70\n5/5 [==============================] - 3s 512ms/step - loss: 5.8099 - sparse_categorical_accuracy: 0.3333 - val_loss: 5.9223 - val_sparse_categorical_accuracy: 0.2667\nEpoch 17/70\n5/5 [==============================] - 3s 511ms/step - loss: 5.7860 - sparse_categorical_accuracy: 0.3178 - val_loss: 5.9081 - val_sparse_categorical_accuracy: 0.3333\nEpoch 18/70\n5/5 [==============================] - 3s 510ms/step - loss: 5.7377 - sparse_categorical_accuracy: 0.3798 - val_loss: 5.8841 - val_sparse_categorical_accuracy: 0.3333\nEpoch 19/70\n5/5 [==============================] - 3s 533ms/step - loss: 5.6804 - sparse_categorical_accuracy: 0.4186 - val_loss: 5.8616 - val_sparse_categorical_accuracy: 0.3333\nEpoch 20/70\n5/5 [==============================] - 3s 539ms/step - loss: 5.6268 - sparse_categorical_accuracy: 0.4806 - val_loss: 5.8336 - val_sparse_categorical_accuracy: 0.4000\nEpoch 21/70\n5/5 [==============================] - 3s 528ms/step - loss: 5.5644 - sparse_categorical_accuracy: 0.5039 - val_loss: 5.8030 - val_sparse_categorical_accuracy: 0.4000\nEpoch 22/70\n5/5 [==============================] - 3s 542ms/step - loss: 5.5018 - sparse_categorical_accuracy: 0.5891 - val_loss: 5.7712 - val_sparse_categorical_accuracy: 0.4000\nEpoch 23/70\n5/5 [==============================] - 3s 529ms/step - loss: 5.4344 - sparse_categorical_accuracy: 0.6434 - val_loss: 5.7385 - val_sparse_categorical_accuracy: 0.4000\nEpoch 24/70\n5/5 [==============================] - 3s 558ms/step - loss: 5.3905 - sparse_categorical_accuracy: 0.6667 - val_loss: 5.6969 - val_sparse_categorical_accuracy: 0.4000\nEpoch 25/70\n5/5 [==============================] - 3s 530ms/step - loss: 5.3505 - sparse_categorical_accuracy: 0.6667 - val_loss: 5.6583 - val_sparse_categorical_accuracy: 0.4000\nEpoch 26/70\n5/5 [==============================] - 3s 574ms/step - loss: 5.2908 - sparse_categorical_accuracy: 0.7054 - val_loss: 5.6218 - val_sparse_categorical_accuracy: 0.4667\nEpoch 27/70\n5/5 [==============================] - 3s 528ms/step - loss: 5.2038 - sparse_categorical_accuracy: 0.7752 - val_loss: 5.5943 - val_sparse_categorical_accuracy: 0.4667\nEpoch 28/70\n5/5 [==============================] - 3s 526ms/step - loss: 5.1422 - sparse_categorical_accuracy: 0.8217 - val_loss: 5.5620 - val_sparse_categorical_accuracy: 0.5333\nEpoch 29/70\n5/5 [==============================] - 3s 529ms/step - loss: 5.0828 - sparse_categorical_accuracy: 0.8837 - val_loss: 5.5179 - val_sparse_categorical_accuracy: 0.5333\nEpoch 30/70\n5/5 [==============================] - 3s 529ms/step - loss: 5.0503 - sparse_categorical_accuracy: 0.8295 - val_loss: 5.4402 - val_sparse_categorical_accuracy: 0.6667\nEpoch 31/70\n5/5 [==============================] - 3s 528ms/step - loss: 4.9342 - sparse_categorical_accuracy: 0.9302 - val_loss: 5.3605 - val_sparse_categorical_accuracy: 0.6667\nEpoch 32/70\n5/5 [==============================] - 3s 543ms/step - loss: 4.8910 - sparse_categorical_accuracy: 0.9070 - val_loss: 5.3092 - val_sparse_categorical_accuracy: 0.6667\nEpoch 33/70\n5/5 [==============================] - 3s 530ms/step - loss: 4.8292 - sparse_categorical_accuracy: 0.9457 - val_loss: 5.2779 - val_sparse_categorical_accuracy: 0.6667\nEpoch 34/70\n5/5 [==============================] - 3s 531ms/step - loss: 4.7383 - sparse_categorical_accuracy: 0.9535 - val_loss: 5.2498 - val_sparse_categorical_accuracy: 0.6667\nEpoch 35/70\n5/5 [==============================] - 3s 541ms/step - loss: 4.6731 - sparse_categorical_accuracy: 0.9767 - val_loss: 5.2193 - val_sparse_categorical_accuracy: 0.6667\nEpoch 36/70\n5/5 [==============================] - 3s 538ms/step - loss: 4.6320 - sparse_categorical_accuracy: 0.9845 - val_loss: 5.1850 - val_sparse_categorical_accuracy: 0.6667\nEpoch 37/70\n5/5 [==============================] - 3s 532ms/step - loss: 4.5950 - sparse_categorical_accuracy: 0.9767 - val_loss: 5.1338 - val_sparse_categorical_accuracy: 0.6667\nEpoch 38/70\n5/5 [==============================] - 3s 561ms/step - loss: 4.5542 - sparse_categorical_accuracy: 0.9845 - val_loss: 5.0858 - val_sparse_categorical_accuracy: 0.6667\nEpoch 39/70\n5/5 [==============================] - 3s 544ms/step - loss: 4.5006 - sparse_categorical_accuracy: 0.9845 - val_loss: 5.0501 - val_sparse_categorical_accuracy: 0.6667\nEpoch 40/70\n5/5 [==============================] - 3s 544ms/step - loss: 4.4426 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0053 - val_sparse_categorical_accuracy: 0.6667\nEpoch 41/70\n5/5 [==============================] - 3s 532ms/step - loss: 4.4107 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9701 - val_sparse_categorical_accuracy: 0.7333\nEpoch 42/70\n5/5 [==============================] - 3s 533ms/step - loss: 4.3852 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9479 - val_sparse_categorical_accuracy: 0.7333\nEpoch 43/70\n5/5 [==============================] - 3s 529ms/step - loss: 4.3280 - sparse_categorical_accuracy: 0.9922 - val_loss: 4.9258 - val_sparse_categorical_accuracy: 0.6667\nEpoch 44/70\n5/5 [==============================] - 3s 531ms/step - loss: 4.2961 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9012 - val_sparse_categorical_accuracy: 0.6667\nEpoch 45/70\n5/5 [==============================] - 3s 530ms/step - loss: 4.2635 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.8891 - val_sparse_categorical_accuracy: 0.6667\nEpoch 46/70\n5/5 [==============================] - 3s 532ms/step - loss: 4.2414 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.8764 - val_sparse_categorical_accuracy: 0.7333\nEpoch 47/70\n5/5 [==============================] - 3s 527ms/step - loss: 4.2225 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.8406 - val_sparse_categorical_accuracy: 0.7333\nEpoch 48/70\n5/5 [==============================] - 3s 528ms/step - loss: 4.2006 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.8067 - val_sparse_categorical_accuracy: 0.7333\nEpoch 49/70\n5/5 [==============================] - 3s 528ms/step - loss: 4.1796 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.7860 - val_sparse_categorical_accuracy: 0.8000\nEpoch 50/70\n5/5 [==============================] - 3s 573ms/step - loss: 4.1603 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.7826 - val_sparse_categorical_accuracy: 0.8000\nEpoch 51/70\n5/5 [==============================] - 3s 530ms/step - loss: 4.1462 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.7705 - val_sparse_categorical_accuracy: 0.8000\nEpoch 52/70\n5/5 [==============================] - 3s 529ms/step - loss: 4.1301 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.7547 - val_sparse_categorical_accuracy: 0.8000\nEpoch 53/70\n5/5 [==============================] - 3s 528ms/step - loss: 4.1207 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.7533 - val_sparse_categorical_accuracy: 0.8000\nEpoch 54/70\n5/5 [==============================] - 3s 531ms/step - loss: 4.1032 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.7367 - val_sparse_categorical_accuracy: 0.8000\nEpoch 55/70\n5/5 [==============================] - 3s 538ms/step - loss: 4.0923 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.6962 - val_sparse_categorical_accuracy: 0.8000\nEpoch 56/70\n5/5 [==============================] - 3s 539ms/step - loss: 4.0833 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.6596 - val_sparse_categorical_accuracy: 0.8000\nEpoch 57/70\n5/5 [==============================] - 3s 528ms/step - loss: 4.0681 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.6280 - val_sparse_categorical_accuracy: 0.8000\nEpoch 58/70\n5/5 [==============================] - 3s 539ms/step - loss: 4.0608 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.6032 - val_sparse_categorical_accuracy: 0.8000\nEpoch 59/70\n5/5 [==============================] - 3s 529ms/step - loss: 4.0491 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.5873 - val_sparse_categorical_accuracy: 0.8000\nEpoch 60/70\n5/5 [==============================] - 3s 529ms/step - loss: 4.0403 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.5706 - val_sparse_categorical_accuracy: 0.8000\nEpoch 61/70\n5/5 [==============================] - 3s 535ms/step - loss: 4.0302 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.5547 - val_sparse_categorical_accuracy: 0.8000\nEpoch 62/70\n5/5 [==============================] - 3s 558ms/step - loss: 4.0204 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.5582 - val_sparse_categorical_accuracy: 0.8000\nEpoch 63/70\n5/5 [==============================] - 3s 544ms/step - loss: 4.0113 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.5788 - val_sparse_categorical_accuracy: 0.8000\nEpoch 64/70\n5/5 [==============================] - 3s 529ms/step - loss: 4.0015 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.5872 - val_sparse_categorical_accuracy: 0.8000\nEpoch 65/70\n5/5 [==============================] - 3s 540ms/step - loss: 3.9934 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.5847 - val_sparse_categorical_accuracy: 0.8000\nEpoch 66/70\n5/5 [==============================] - 3s 529ms/step - loss: 3.9837 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.5825 - val_sparse_categorical_accuracy: 0.8000\nEpoch 67/70\n5/5 [==============================] - 3s 540ms/step - loss: 3.9752 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.5641 - val_sparse_categorical_accuracy: 0.8000\nEpoch 68/70\n5/5 [==============================] - 3s 540ms/step - loss: 3.9672 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.5406 - val_sparse_categorical_accuracy: 0.8000\nEpoch 69/70\n5/5 [==============================] - 3s 531ms/step - loss: 3.9582 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.5157 - val_sparse_categorical_accuracy: 0.8000\nEpoch 70/70\n5/5 [==============================] - 3s 527ms/step - loss: 3.9490 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.5004 - val_sparse_categorical_accuracy: 0.8000\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7ac1cd024490>"},"metadata":{}}]},{"cell_type":"code","source":"loss, accuracy = classifier_model.evaluate(np.asarray(x_test), np.asarray(y_test))\n\nprint(f'Loss: {loss}')\nprint(f'Accuracy: {accuracy}')","metadata":{"execution":{"iopub.status.busy":"2023-10-04T18:28:48.438440Z","iopub.execute_input":"2023-10-04T18:28:48.439011Z","iopub.status.idle":"2023-10-04T18:28:48.754971Z","shell.execute_reply.started":"2023-10-04T18:28:48.438979Z","shell.execute_reply":"2023-10-04T18:28:48.753894Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"2/2 [==============================] - 0s 35ms/step - loss: 4.3145 - sparse_categorical_accuracy: 0.8611\nLoss: 4.314503192901611\nAccuracy: 0.8611111044883728\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Flan-T5 with LORA (HuggingFace)","metadata":{}},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=32, # Rank\n    lora_alpha=32,\n    target_modules=[\"q\", \"v\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n)\npeft_model = get_peft_model(original_model, \n                            lora_config)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T19:37:15.826086Z","iopub.execute_input":"2024-06-07T19:37:15.826364Z","iopub.status.idle":"2024-06-07T19:37:16.515593Z","shell.execute_reply.started":"2024-06-07T19:37:15.826339Z","shell.execute_reply":"2024-06-07T19:37:16.514592Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"output_dir = f'/kaggle/working/peft-model-training-{str(int(time.time()))}'\n\npeft_training_args = TrainingArguments(\n    output_dir=output_dir,\n    auto_find_batch_size=True,\n    learning_rate=1e-3, # Higher learning rate than full fine-tuning.\n    num_train_epochs=1,\n    logging_steps=1,\n    max_steps=1    \n)\n    \npeft_trainer = Trainer(\n    model=peft_model,\n    args=peft_training_args,\n    train_dataset=tokenized_datasets['train'],\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-07T19:37:16.517393Z","iopub.execute_input":"2024-06-07T19:37:16.517698Z","iopub.status.idle":"2024-06-07T19:37:17.657384Z","shell.execute_reply.started":"2024-06-07T19:37:16.517672Z","shell.execute_reply":"2024-06-07T19:37:17.656383Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"peft_trainer.train()\n\npeft_model_path=\"/kaggle/working/peft-model-checkpoint-local\"\n\npeft_trainer.model.save_pretrained(peft_model_path)\ntokenizer.save_pretrained(peft_model_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T19:37:17.658605Z","iopub.execute_input":"2024-06-07T19:37:17.658908Z","iopub.status.idle":"2024-06-07T19:39:04.975335Z","shell.execute_reply.started":"2024-06-07T19:37:17.658882Z","shell.execute_reply":"2024-06-07T19:39:04.974351Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240607_193830-nqtyct2r</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/kolosus/huggingface/runs/nqtyct2r' target=\"_blank\">electric-glitter-2</a></strong> to <a href='https://wandb.ai/kolosus/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/kolosus/huggingface' target=\"_blank\">https://wandb.ai/kolosus/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/kolosus/huggingface/runs/nqtyct2r' target=\"_blank\">https://wandb.ai/kolosus/huggingface/runs/nqtyct2r</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 00:00, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>49.250000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/peft-model-checkpoint-local/tokenizer_config.json',\n '/kaggle/working/peft-model-checkpoint-local/special_tokens_map.json',\n '/kaggle/working/peft-model-checkpoint-local/spiece.model',\n '/kaggle/working/peft-model-checkpoint-local/added_tokens.json',\n '/kaggle/working/peft-model-checkpoint-local/tokenizer.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Making Predictions.","metadata":{}},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/emonlp-interiit-techsoc-aiclub/test.csv\")\ntest_data.head(5)\n\nx_predict = np.asarray(test_data.Text)\npredicted_labels = []\n","metadata":{"execution":{"iopub.status.busy":"2024-06-07T19:39:09.318718Z","iopub.execute_input":"2024-06-07T19:39:09.319079Z","iopub.status.idle":"2024-06-07T19:39:09.330518Z","shell.execute_reply.started":"2024-06-07T19:39:09.319049Z","shell.execute_reply":"2024-06-07T19:39:09.329527Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from peft import PeftModel, PeftConfig\n\npeft_model_base = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\npeft_model = PeftModel.from_pretrained(peft_model_base, \n                                       '/kaggle/working/peft-model-checkpoint-local', \n                                       torch_dtype=torch.bfloat16,\n                                       is_trainable=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T19:39:09.895898Z","iopub.execute_input":"2024-06-07T19:39:09.896252Z","iopub.status.idle":"2024-06-07T19:39:16.627321Z","shell.execute_reply.started":"2024-06-07T19:39:09.896222Z","shell.execute_reply":"2024-06-07T19:39:16.626318Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"for x in x_predict:\n    index = 200\n    prompt = '''Identify the sentiment of the following dialogue from the given labels. Provide a one-word sentiment only.\n    Labels: {}\n\n    Dialogue: {}\n    Sentiment:\n    '''.format(labels, x)\n    \n    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n    peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n    peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n    \n    predicted_labels.append(peft_model_text_output)\n    \nemotion = pd.DataFrame({'Emotion' : predicted_labels})\n    ","metadata":{"execution":{"iopub.status.busy":"2024-06-07T19:39:20.455963Z","iopub.execute_input":"2024-06-07T19:39:20.456314Z","iopub.status.idle":"2024-06-07T19:41:16.056372Z","shell.execute_reply.started":"2024-06-07T19:39:20.456285Z","shell.execute_reply":"2024-06-07T19:41:16.055214Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# # y_predict = classifier_model.predict(x_predict, verbose = 1)\n\n# # Creating DataFrame of predictions.\n# # predicted_labels = np.argmax(y_predict, axis=1)\n# emotion = pd.DataFrame({'Emotion' : predicted_labels})\n# emotion = emotion.replace(labels_dictionary_reverse)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T19:22:17.310021Z","iopub.status.idle":"2024-06-07T19:22:17.310466Z","shell.execute_reply.started":"2024-06-07T19:22:17.310236Z","shell.execute_reply":"2024-06-07T19:22:17.310259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating final csv file.\nout = pd.DataFrame({'ID': test_data['ID'], 'Emotion' : emotion['Emotion']})\nout.to_csv('submission.csv', index=False)\nout.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T19:41:16.058181Z","iopub.execute_input":"2024-06-07T19:41:16.058602Z","iopub.status.idle":"2024-06-07T19:41:16.081132Z","shell.execute_reply.started":"2024-06-07T19:41:16.058570Z","shell.execute_reply":"2024-06-07T19:41:16.080142Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"   ID Emotion\n0   0     joy\n1   1   anger\n2   2     joy\n3   3    love\n4   4     joy","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>joy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}